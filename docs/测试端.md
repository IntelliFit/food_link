这份需求文档旨在为 **Food Link** 项目开发一套“开发者实验流水线（Developer Experiment Pipeline）”。该流水线将通过数据驱动的方式，利用“金标准”数据集对比不同的 AI 识别方法，从而量化并提升食物分析的准确性能。

---

# Food Link 开发者实验流水线（V1.0）需求文档

## 1. 项目背景与目标

目前 Food Link 已实现基于阿里云 DashScope 的基础拍照识别功能。为了进一步提升模型在不同拍摄角度、参照物及提示词下的性能，我们需要建立一套标准化的实验评估体系，支持核心测试者（如博主“好人松松”）采集真值数据，并由工程师快速迭代算法方案。

## 2. 核心功能需求

### 2.1 云端金标准数据集管理 (Gold Standard Dataset)

* **数据集定义**：后端需支持创建多个命名数据集（如“俯拍对照组”、“标准餐盒组”）。
* **样本构成**：每个样本需包含：
* 原始图片（存储于云端）。
* **金标准数据 (Ground Truth)**：食物的真实名称、真实称重克数（精确到1g）及权威营养成分。
* **环境元数据 (Metadata)**：手动标记的视角（平拍/45度/俯拍）、光照情况、是否有参照物。


* **管理接口**：提供批量拉取数据集图片及其对应金标准的 API。

### 2.2 多版本方法对比系统 (Multi-Method Logic)

* **方案抽象**：将 AI 分析流程代码化为可配置的“方法（Method）”。
* **变量控制**：支持定义不同的提示词模板 (Prompt Template)、模型参数（如 Temperature）及图像预处理逻辑。


* **多方法并跑**：后端应能针对同一个数据集样本，同时运行多个方法（如 `method_v1_base` vs `method_v2_with_box_logic`），并分别记录输出结果。

### 2.3 实验流水线运行与评估 (Evaluation Pipeline)

* **自动化跑测**：支持通过脚本或管理后台启动实验，自动遍历指定数据集并调用指定方法。
* **误差计算指标**：系统自动比对 AI 预测值与金标准，计算核心指标：
* **MAPE (平均绝对百分比误差)**：`(预测重量 - 真实重量) / 真实重量`。
* **单项准确率**：食物类别识别的成功率。


* **坏例记录 (Bad Cases)**：自动筛选并汇总误差超过设定阈值（如 >30%）的样本，便于针对性优化。

## 3. 核心角色与流程变更

### 3.1 实验者权限与入口 (Tester Portal)

* **角色管理**：在 `weapp_user` 表中增加 `role` 字段，识别 `tester`（测试者）身份。
* **移动端实验室模式**：
* **分析页 (`AnalyzePage`)**：针对测试者显示“实验参数”勾选框（选择当前拍摄视角、参照物类型），并将这些元数据随图片一并发往后端。
* **结果页 (`ResultPage`)**：测试者可在此输入实测重量。点击“确认记录”时，后端需将图片、AI 结果、测试者填写的真值及元数据存入实验数据库，而非仅在本地缓存。



### 3.2 后端接口升级

* **`POST /api/analyze` 升级**：支持接收 `experimentConfig` 参数，根据不同配置路由至不同的提示词处理逻辑。
* **新增 `POST /api/experiment/log**`：用于持久化存储测试者提交的实验样本与真值。
* **新增 `GET /api/experiment/report**`：汇总不同方法、不同数据集下的性能对比报表。

## 4. 实验场景示例

* **场景 A（固定方法，测数据集）**：运行同一套提示词，对比“45度斜拍”与“垂直俯拍”哪种数据集的 MAPE 更低，从而确定推荐给用户的官方拍摄指南。
* **场景 B（固定数据集，测方法）**：在同一批“带参照物”的照片集上，测试增加“逻辑推理步骤”的提示词是否能显著降低重量估算的误差。

## 5. 技术约束

* **数据库**：所有实验数据、金标准、元数据均需持久化存储于 Supabase。
* **安全性**：实验管理接口及实验室模式入口需通过后端 `middleware.py` 进行严格的权限校验。
* **可扩展性**：提示词管理需模块化，支持在不重启服务的情况下动态更新实验提示词。